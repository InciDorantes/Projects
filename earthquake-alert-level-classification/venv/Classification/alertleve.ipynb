{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'!pip install scikit-learn\\n!pip install matplotlib\\n!pip install pandas \\n!pip install numpy \\n!pip install seaborn\\n!pip install imbalanced-learn\\n%matplotlib inline\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install pandas \n",
    "!pip install numpy \n",
    "!pip install seaborn\n",
    "!pip install imbalanced-learn\n",
    "%matplotlib inline'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Preparing data<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7714, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "time                object\n",
       "latitude           float64\n",
       "longitude          float64\n",
       "depth              float64\n",
       "mag                float64\n",
       "magType             object\n",
       "nst                float64\n",
       "gap                float64\n",
       "dmin               float64\n",
       "rms                float64\n",
       "net                 object\n",
       "id                  object\n",
       "updated             object\n",
       "place               object\n",
       "type                object\n",
       "horizontalError    float64\n",
       "depthError         float64\n",
       "magError           float64\n",
       "magNst             float64\n",
       "status              object\n",
       "locationSource      object\n",
       "magSource           object\n",
       "Alert               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/earthquakes.csv\")\n",
    "df = df.fillna(0)\n",
    "\n",
    "print(df.shape)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns name: Index(['time', 'latitude', 'longitude', 'depth', 'mag', 'magType', 'nst',\n",
      "       'gap', 'dmin', 'rms', 'net', 'id', 'updated', 'place', 'type',\n",
      "       'horizontalError', 'depthError', 'magError', 'magNst', 'status',\n",
      "       'locationSource', 'magSource', 'Alert', 'type_value'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Alert\n",
       "green     7386\n",
       "yellow     245\n",
       "orange      51\n",
       "red         32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typescat = {\n",
    "    \"earthquake\":1,\n",
    "    \"volcanic eruption\":2,\n",
    "    \"nuclear explosion\":3\n",
    "}\n",
    "df['type_value'] = df['type'].map(typescat)\n",
    "print(f\"Columns name: {df.columns}\")\n",
    "df['Alert'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "depth: The depth at which the earthquake occurred, typically measured in kilometers below the Earth's surface.\n",
    "\n",
    "mag: The magnitude of the earthquake, representing the energy released by the seismic event. In this case, a value of 8.6 indicates a very large earthquake.\n",
    "\n",
    "dmin: The minimum distance between the earthquake's epicenter and the nearest seismic station, measured in degrees.\n",
    "\n",
    "rms: The root mean square of the amplitude of the seismic waves, representing the strength of the seismic signal.\n",
    "\n",
    "type: The type of event, such as \"volcanic eruption\" or \"earthquake.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Pandas data fram to a Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['depth', 'mag', 'dmin', 'rms', 'type_value']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green -> 0\n",
      "orange -> 1\n",
      "red -> 2\n",
      "yellow -> 3\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Alert'])\n",
    "for index, label in enumerate(le.classes_):\n",
    "    print(f\"{label} -> {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (5399, 5) (5399,)\n",
      "Test set: (2315, 5) (2315,)\n"
     ]
    }
   ],
   "source": [
    "#30%\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobremuestreo (para contrarrestar que hay muchos green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Distribution: Counter({np.int64(0): 5171, np.int64(3): 5171, np.int64(1): 5171, np.int64(2): 5171})\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verifica la nueva distribución de clases\n",
    "print(\"SMOTE Distribution:\", Counter(y_train_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>K Nearest Neighbor Classification<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV to find the perfects hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Best score: 0.9601140273486098\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': range(1, 50),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['minkowski', 'manhattan', 'euclidean']\n",
    "}\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = grid_search.best_params_.get('n_neighbors')\n",
    "#train model \n",
    "neigh = KNeighborsClassifier(n_neighbors=k, weights=grid_search.best_params_.get('weights'), metric=grid_search.best_params_.get('metric')). fit(X_train_resampled,  y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción:[0 0 0 2 0 0 0 0 0 0]\n",
      "El y_test: [0 0 0 2 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Predict\n",
    "yhat = neigh.predict(X_test)\n",
    "print(f\"Predicción:{yhat[211:221]}\")\n",
    "print(f\"El y_test: {y_test[211:221]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy:  0.9998147805149101\n",
      "Test set Accuracy:  0.8665226781857451\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\n",
    "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Classificaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_resampled, label=y_train_resampled)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective':'multi:softmax',\n",
    "    'max_depth':4,\n",
    "    'num_class':4,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'min_child_weight': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(params, dtrain, num_boost_round=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción:[0. 0. 0. 2. 0. 0. 1. 0. 0. 0.]\n",
      "El y_test: [0 0 0 2 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "y_pred = bst.predict(dtest)\n",
    "print(f\"Predicción:{y_pred[211:221]}\")\n",
    "print(f\"El y_test: {y_test[211:221]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8078\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"XGBoost Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
